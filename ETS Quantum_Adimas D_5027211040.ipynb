{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["#Import packages\n","\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import os\n","import path\n","\n","import torch\n","import torchvision\n","from torch.utils import data\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data.sampler import SubsetRandomSampler"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["def target_to_oh(target):\n","    NUM_CLASS = 5  # hard code here, can do partial\n","    one_hot = torch.eye(NUM_CLASS)[target]\n","    return one_hot"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[],"source":["transform_bunch = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n","                                      transforms.RandomVerticalFlip(p=0.5),\n","                                      transforms.ToTensor()])\n","#                                       transforms.Normalize((0.5139, 0.2727, 0.0891), (0.1533, 0.0909, 0.0400))])"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["ds = torchvision.datasets.ImageFolder(\"../../gaussian_filtered_images/gaussian_filtered_images\", transform_bunch, target_transform = target_to_oh)"]},{"cell_type":"code","execution_count":32,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1., 0., 0., 0., 0.])\n"]}],"source":["for x,y in ds:\n","    print(y)\n","    break"]},{"cell_type":"code","execution_count":33,"metadata":{"trusted":true},"outputs":[],"source":["percent = 0.2\n","\n","split = int(len(ds) * percent)\n","\n","indices = list(range(len(ds)))"]},{"cell_type":"code","execution_count":34,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["732"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["split"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":35,"metadata":{"trusted":true},"outputs":[],"source":["train_sampler = SubsetRandomSampler(indices[split:])\n","\n","valid_sampler = SubsetRandomSampler(indices[:split])"]},{"cell_type":"code","execution_count":36,"metadata":{"trusted":true},"outputs":[],"source":["bs = 100\n","\n","dl = data.DataLoader(ds, bs, sampler=train_sampler)\n","\n","valid_dl = data.DataLoader(ds, bs, sampler=valid_sampler)"]},{"cell_type":"code","execution_count":37,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([100, 3, 224, 224]) torch.Size([100, 5])\n"]}],"source":["xx = 0\n","yy = 0\n","\n","for x,y in valid_dl:\n","    print(x.shape,y.shape)\n","    xx = x\n","    yy = y\n","    break"]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0.]])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["yy"]},{"cell_type":"code","execution_count":39,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["{'Mild': 0, 'Moderate': 1, 'No_DR': 2, 'Proliferate_DR': 3, 'Severe': 4}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["#looks like something is off... Yup --> We can just transform it at the end\n","ds.class_to_idx"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[],"source":["#Now I'll be making the model! It'll take elements off of nn.Module\n","class cnnmaker(nn.Module):\n","    #Initialization will only take in input channels\n","    def __init__(self, input_channels):\n","        super().__init__()\n","        \n","        #I looked at what the resnet architechture looked like and just implmented the block types (not the residual part just yet)\n","        def block(in_chan):\n","            return nn.Sequential(nn.Conv2d(in_chan, in_chan * 2, 3, 2, 1, padding_mode = \"reflect\"),\n","                                nn.BatchNorm2d(in_chan*2),\n","                                nn.ReLU())\n","        \n","        self.model = nn.Sequential(block(input_channels),\n","                                  block(input_channels*2),\n","                                  block(input_channels*4),\n","                                  block(input_channels*8),\n","                                  block(input_channels*16))\n","        \n","        self.second_model = nn.Sequential(nn.Linear(4704, 500),\n","                                         nn.Dropout(),\n","                                         nn.ReLU(),\n","                                         nn.Linear(500, 100),\n","                                         nn.Dropout(),\n","                                         nn.ReLU(),\n","                                         nn.Linear(100, 5))\n","    #The forward pass when you call it   \n","    def forward(self, images):\n","        pre_proc = self.model(images)\n","#         print(pre_proc.shape)\n","        \n","        formatted = torch.reshape(pre_proc, (images.shape[0], -1))\n","        \n","        return self.second_model(formatted)"]},{"cell_type":"code","execution_count":41,"metadata":{"trusted":true},"outputs":[],"source":["model = cnnmaker(3)"]},{"cell_type":"code","execution_count":42,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["cnnmaker(\n","  (model): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (4): Sequential(\n","      (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n","      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (second_model): Sequential(\n","    (0): Linear(in_features=4704, out_features=500, bias=True)\n","    (1): Dropout(p=0.5, inplace=False)\n","    (2): ReLU()\n","    (3): Linear(in_features=500, out_features=100, bias=True)\n","    (4): Dropout(p=0.5, inplace=False)\n","    (5): ReLU()\n","    (6): Linear(in_features=100, out_features=5, bias=True)\n","  )\n",")"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":43,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2458905\n"]}],"source":["#Look at how many parameters\n","total = 0\n","for param in model.parameters():\n","    if param.requires_grad:\n","        total += param.numel()\n","\n","print(total)"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[],"source":["loss_func = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters())"]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[],"source":["# model = model.to('cuda')\n","# loss_func = loss_func.to('cuda')"]},{"cell_type":"code","execution_count":46,"metadata":{"trusted":true},"outputs":[],"source":["def accuracy(preds, target):\n","    correct = (preds == target).float()\n","    accuracy = correct.sum() / len(correct)\n","    return accuracy"]},{"cell_type":"code","execution_count":47,"metadata":{"trusted":true},"outputs":[],"source":["# def train():\n","#     model.train()\n","    \n","#     for image, label in dl:\n","#         image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.FloatTensor)\n","#         optimizer.zero_grad()\n","#         prediction = model(image)\n","        \n","#         loss = loss_func(prediction, label)\n","        \n","#         loss.backward()\n","        \n","#         optimizer.step()\n","    \n","#     with torch.no_grad():\n","#         total_iter = 0\n","#         total_acc = 0\n","#         for image, label in valid_dl: \n","#             image, label = image.to('cuda', dtype=torch.float), label.to('cuda', dtype=torch.float)\n","#             prediction = model(image)\n","#             total_acc += accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","#             total_iter += 1\n","#             if total_iter == 7:\n","#                 print(\"valid\",total_acc/total_iter)\n","#                 total_iter = 0\n","#                 total_acc = 0\n","#                 for image, label in dl: \n","#                     image, label = image.to('cuda', dtype=torch.float), label.to('cuda', dtype=torch.float)\n","#                     prediction = model(image)\n","#                     total_acc += accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","#                     total_iter += 1\n","#                     if total_iter == 7:\n","#                         print(total_acc/total_iter)\n","#                         return \"done\""]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["def train():\n","    model.train()\n","    \n","    for image, label in dl:\n","        # Memastikan tensor berada di perangkat CPU\n","        image, label = image.type(dtype=torch.FloatTensor), label.type(dtype=torch.FloatTensor)\n","        optimizer.zero_grad()\n","        prediction = model(image)\n","        \n","        loss = loss_func(prediction, label)\n","        \n","        loss.backward()\n","        \n","        optimizer.step()\n","    \n","    with torch.no_grad():\n","        total_iter = 0\n","        total_acc = 0\n","        for image, label in valid_dl: \n","            # Memastikan tensor berada di perangkat CPU\n","            image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","            prediction = model(image)\n","            total_acc += accuracy(torch.argmax(prediction, dim=1).float(), torch.argmax(label, dim=1).float())\n","            total_iter += 1\n","            if total_iter == 7:\n","                print(\"valid\", total_acc / total_iter)\n","                total_iter = 0\n","                total_acc = 0\n","                for image, label in dl: \n","                    # Memastikan tensor berada di perangkat CPU\n","                    image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","                    prediction = model(image)\n","                    total_acc += accuracy(torch.argmax(prediction, dim=1).float(), torch.argmax(label, dim=1).float())\n","                    total_iter += 1\n","                    if total_iter == 7:\n","                        print(total_acc / total_iter)\n","                        return \"done\"\n"]},{"cell_type":"code","execution_count":49,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)"]},{"cell_type":"code","execution_count":50,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.2543)\n","tensor(0.7571)\n","valid tensor(0.3329)\n","tensor(0.7743)\n","valid tensor(0.3371)\n","tensor(0.7700)\n","valid tensor(0.3343)\n","tensor(0.8029)\n"]}],"source":["for _ in range(4):\n","    train()"]},{"cell_type":"code","execution_count":51,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":52,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.3743)\n","tensor(0.7843)\n","valid tensor(0.3586)\n","tensor(0.8129)\n","valid tensor(0.4071)\n","tensor(0.7943)\n","valid tensor(0.4186)\n","tensor(0.7843)\n","valid tensor(0.3929)\n","tensor(0.7714)\n","valid tensor(0.3743)\n","tensor(0.7986)\n","valid tensor(0.3843)\n","tensor(0.8171)\n","valid tensor(0.3229)\n","tensor(0.8014)\n","valid tensor(0.3686)\n","tensor(0.7886)\n","valid tensor(0.4029)\n","tensor(0.7986)\n"]}],"source":["for _ in range(10):\n","    train()"]},{"cell_type":"code","execution_count":53,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.3929)\n","tensor(0.7814)\n","valid tensor(0.3814)\n","tensor(0.7971)\n","valid tensor(0.4129)\n","tensor(0.8186)\n","valid tensor(0.4386)\n","tensor(0.8114)\n","valid tensor(0.3857)\n","tensor(0.8014)\n","valid tensor(0.3686)\n","tensor(0.8029)\n","valid tensor(0.3986)\n","tensor(0.8014)\n","valid tensor(0.3771)\n","tensor(0.8100)\n","valid tensor(0.4057)\n","tensor(0.8129)\n","valid tensor(0.3657)\n","tensor(0.7986)\n","valid tensor(0.3971)\n","tensor(0.8243)\n","valid tensor(0.3700)\n","tensor(0.8057)\n","valid tensor(0.3571)\n","tensor(0.8286)\n","valid tensor(0.3771)\n","tensor(0.8371)\n","valid tensor(0.3900)\n","tensor(0.8171)\n","valid tensor(0.3671)\n","tensor(0.8186)\n","valid tensor(0.4214)\n","tensor(0.8500)\n","valid tensor(0.3729)\n","tensor(0.8486)\n","valid tensor(0.4100)\n","tensor(0.8129)\n","valid tensor(0.4057)\n","tensor(0.8386)\n"]}],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["valid tensor(0.4029)\n","tensor(0.8257)\n","valid tensor(0.3514)\n","tensor(0.8414)\n","valid tensor(0.4300)\n","tensor(0.8086)\n","valid tensor(0.3714)\n","tensor(0.8571)\n","valid tensor(0.4157)\n","tensor(0.8514)\n","valid tensor(0.4029)\n","tensor(0.8486)\n","valid tensor(0.3743)\n","tensor(0.8457)\n"]}],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for _ in range(20):\n","    train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xxx = 0\n","yyy = 0\n","\n","for x,y in dl:\n","    print(x.shape,y.shape)\n","    xxx = x\n","    yyy = y\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["yyy = yyy.type(dtype=torch.FloatTensor)\n","torch.argmax(yyy, dim = 1).float()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xxx = xxx.type(dtype=torch.FloatTensor)\n","prediction = model(xxx)\n","torch.argmax(prediction, dim = 1).float()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["accuracy(torch.argmax(prediction, dim = 1).float(),torch.argmax(yyy, dim = 1).float())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with torch.no_grad():\n","    total_iter = 0\n","    total_acc = 0\n","    for image, label in dl: \n","        image, label = image.to('cpu', dtype=torch.float), label.to('cpu', dtype=torch.float)\n","        prediction = model(image)\n","        h = accuracy(torch.argmax(prediction, dim = 1).float(), torch.argmax(label, dim = 1).float())\n","        print(h)\n","        total_acc += h\n","        total_iter += 1\n","        if total_iter == 20:\n","            print(total_acc/total_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
